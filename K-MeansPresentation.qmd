---
title: "K-Means Presentation"
format: 
  revealjs:
    incremental: true
embed-resources: true
---
```{r}
load("df_norm.RData")
```
## An Introduction to K-means clustering

::: incremental
Finding meaningful patterns within data has become obtrusive as data collection and management continues to grow at an unprecedented rate.

K-means clustering caters to such highly voluminous & unlabeled data.

By the end of this presentation we will have discussed the following concepts of k-means clustering:
:::

::: {.fragment .fade-up}
-   Unsupervised learning
-   Clustering
-   Mathematical foundation of the k means algorithm by the Euclidean Distance.
:::

## An Introduction to K-means clustering

::: nonincremental
There are 5 main steps to execute the k-means clustering method.
:::

::: { .fragent .fade-up}
-   Assign all data points to a cluster noted as $k$.
-   Set $k$ random seed points.
-   Reassign all data points to a cluster using distance to seed point.
-   Compute the mean center of each new cluster noted as a centroid.
-   Loop the re-assignment step of all data points to a new centroid based on its minimized relocation, until the centroid does not change.
:::

::: notes
We will discuss the 5 main steps of the method and apply it to an eCommerce data set but first it is necessary to introduce some components needed to set up the k-means clustering analysis.

We will employ the k-means clustering algorithm to gain insights on customer segmentation in eCommerce data for a retail store based in the UK.

K-means clustering will be used to classify consumer bases into discrete clusters based on shared characteristics. These clusters will be interpreted and discussed at the end of the analysis.
:::

## What is Unsupervised learning

::: incremental
-   Statistical modeling technique used to categorize/group data without the assistance of historical results or human intervention.
-   Autonomous data categorization
-   Creates a data driven outcome
:::

::: notes
The autonomous reassignment of data to a centroid is the act that makes this method a form of unsupervised learning.

This is rather a data driven outcome as the data fall into different clusters, new centroids are calculated based on those members.

Initial centroids are generated randomly in this generic model for K-means clustering, we will discuss how other methods intend to improve the model with a modified centroid selection.
:::

## Clustering

::: incremental
-   Clustering is the act of partitioning data into meaningful groups based on similarity in attributes.

-   The goal of clustering is to create insightful clusters to better understand connections in the data.
:::

---

::: columns
::: {.column width="60%"}
::: fragment
-   $k=4$, the seed point are green, forming 4 respective clusters
-   Once the initial assignemnt of centroids is made the Euclidean distance is used to establish cluster members by minimal distance noted as the red lines in the figure.
:::
:::
::: {.column width="40%"}
::: fragment
![centroids](centroids.png)
:::
:::
:::
::: notes
This example the data are clustered based on 4 randomly set seed centers, k=4.
:::
## Euclidean Distance

::: columns
::: {.column width="60%"}
::: fragment
-   Euclidean distance can be employed as a key metric to measure the dissimilarity between data points, facilitating the grouping of similar data instances into clusters using the K-Means clustering algorithm.
:::

::: fragment
$$d(x,C_i)=sqrt(\sum_{i=1}^{N} (x_jâˆ’C_{ij})^2)$$
:::
:::

::: {.column width="40%"}
::: fragment
Objective Function:
- The k-means clustering objective is to minimize the within-cluster variance.
:::

::: fragment
It is formulated as:

$$ d(x,C_i)=(\sum_{i=1}^{k}*\sum_{x \in C_i}^{}(||x-\mu_i||)^2) $$
:::
:::
:::

## Euclidean Distance

::: nonincremental
-   $k$ is the number of clusters.

-   $C_i$ represents the number of points in the cluster $i$

-   $\mu_i$ represents the centroid mean of cluster $i$

-   In this context, similarity is inversely related to the Euclidean distance

-   The smaller the distance, the greater the similarity between objects
:::

---

::: nonincremental
::: columns
::: {.column width="50%"}
-   K-means clustering reassigns the data points to each cluster based on the Euclidean Distance calculation.

-   Each centroid location is updated by taking the position at each clusters mean center.
:::

::: {.column width="50%"}
![data points reassigned to centroids](clusters.png)
:::
:::
:::

## Determine K

::: incremental
-   The elbow method plots the within cluster sum of squares by $k$.
:::

::: fragment
```{r, `code-line-numbers` "5-9"}
#| echo: fenced
# Create an empty vector to store WCSS values
wcss <- vector("numeric", length = 10)
# Iterate over a range of K values (e.g., from 1 to 10)
for (i in 1:10) {
  model <- kmeans(df_norm[c("Sales", "Orders", "AvgSale")], centers = i, nstart = 10)
  wcss[i] <- ceiling(model$tot.withinss)
}
```
:::

::: notes
-wcss notates the within cluster sums of squares total.

-While cluster numbers are selected before the analysis, the cluster location in the data is randomly generated as mentioned.
:::

## Elbow Method

::: panel-tabset
### Code

```{r, `code-line-numbers`"6-11"}
#| echo: true
#| fig-width: 10
#| fig-height: 4.5
library(ggplot2)
# Plot the WCSS values against the number of clusters
ggplot(data.frame(K=1:10, WCSS=wcss), aes(x=K, y=WCSS)) +
  geom_line() +
  geom_point() +
  labs(title="Elbow Method to Find Optimal K", x="Number of Clusters (K)", y="Within-Cluster-Sum-of-Squares (WCSS)") +
  scale_x_continuous(breaks = seq(0, 10, by = 1))
```

### Plot

![Elbow Method](ElbowMethod.png)
:::

::: notes
Based on the results of the Elbow Method, above, the total WCSS appears to decrease less and less starting at 4. This gives us the ideal starting value for the initial number of clusters in the K-means model.
:::

## Data Preparation

::: panel-tabset
### Raw Data

![Raw Customer Data](rawdata.png)

### Cleaned Data

![Data by Customer acquisition](customerdata.png)
:::

::: notes
Quantity and UnitPrice are multiplied together to create total We want to exclude returns to avoid negative values for Quantity. Sales is the sum total derived from the new total column Orders are calculated by Invoice date to account for all transactions. Average sale is the difference of Sales and Orders.
:::

## The Analysis

## Cluster Interpretation

## Future Works
