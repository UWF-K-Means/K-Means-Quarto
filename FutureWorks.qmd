# Future Works {.unnumbered}

The k-means clustering method has been an idea, discussed and explored by mathematicians, for over half a century. One of the first instances comes from a study in 1965 which outlines a more modern approach to the method, including an approach to find the ideal number of clusters; presented by Geoffrey Ball and David Hall [@Ball1965]. Over the past sixty years, improvements and additions have been made to the base k-means methodology in order to optimize performance and increase scalability. Today, there are many different approaches to the method, including but not limited to finding the optimal value of K, and mixture models to increase accuracy. With the increase in general computing power and the development of additional algorithms, practitioners have implemented different distance functions for assigning data to centroids, included additional methods to refine data during preprocessing, supporting processes to support the base algorithm, and generally increased the accuracy and performance of a very basic approach to unsupervised data mining. Given the time constraint of this study, most of the improvements and suggested approaches to the k-means algorithm were not able to be explored. Future studies may include a comparison between different distance formulas such as the Mahatten distance and Chebyshev distance, the use of additional k selection methods such as the Empirical and Silhouette methods, and the use of principal component analysis or other dimensionality reduction techniques to improve efficiency and overall clustering results.
