# Analysis {.unnumbered}

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
library(rlang)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(sjPlot)
library(MASS)
library(tidyr)
library(sjmisc)
library(sjlabelled)
library(naniar)
library(cluster)
library(factoextra)
library(plotly)
library(broom)
```

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
data <- read_csv("data.csv")
save(data, file = "data.RData")
```

To begin, an appropriate data source is identified. The data used in this analysis comes from UC Irvine's Machine Learning Repository, [@data]. In order to maintain a healthy set of usable data, disruptive null values from the base data are removed and a subsequent view of data descriptions are explored.

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
InvoiceNo <- c("Length: 406829","Class: character","Mode: character","NA","NA","NA")
StockCode <- c("Length: 406829","Class: character","Mode: character","NA","NA","NA")
Description <- c("Length: 406829","Class: character","Mode: character","NA","NA","NA")
Quantity <- c("Min.: -80995.00","1st Qu.: 2.00","Median: 5.00","Mean: 12.06","3rd Qu.: 12.00","Max.: 80995.00")
InvoiceDate <- c("Length: 406829","Class: character","Mode: character","NA","NA","NA")
UnitPrice <- c("Min.: 0.00","1st Qu.: 1.25","Median: 1.95","Mean: 3.46","3rd Qu.: 3.75","Max.: 38970.00")
CustomerID <- c("Min.: 12346","1st Qu.: 13953","Median: 15152","Mean: 15288","3rd Qu.: 16791","Max.: 18287")
Country <- c("Length: 406829","Class: character","Mode: character","NA","NA","NA")
```

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
data_nulls_removed <- na.omit(data)
save(data_nulls_removed, file = "data_nulls_removed.RData")
data_summary <- data.frame(InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country)
data_summary
```

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
rm(InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country)
```

The descriptions show that the data, excluding observations with null values, consists of $406,829$ total observations. This specific data set originates from an online retailer located in the United Kingdom, but provides retail service to many different countries and regions. From the summary of the chosen data set, $8$ variables are identified: *InvoiceNo*, *StockCode*, *Description*, *Quantity*, *InvoiceDate*, *UnitPrice*, *CustomerID*, and *Country*.

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
head(data_nulls_removed,10)
```

The frequency of purchases by *Country* may help provide some context about the regional distribution of customers, as well as the possible variety of customers:

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
topCountries_all <- data_nulls_removed %>% count(Country) %>% slice_max(n, n = 10, with_ties = FALSE)

ggplot(data = topCountries_all, mapping = aes(x=Country, y=n, fill=Country)) + 
  geom_bar(stat="identity") +
  labs(title = "Top 10 Countries", y="Total Lifetime Transactions") +
  theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))
```

It quickly becomes apparent that an overwhelming amount of data comes from the UK, as expected, which could skew the results during any analysis. In order to avoid this, a subset of data is generated which excludes data associated with the UK.

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
data_no_uk <- data_nulls_removed[data_nulls_removed$Country != "United Kingdom",]
save(data_no_uk, file = "data_no_uk.RData")
```

With the UK data removed, the top $10$ frequencies are examined:

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
topCountries <- data_no_uk %>% count(Country) %>% slice_max(n, n = 10, with_ties = FALSE) 

ggplot(data = topCountries, mapping = aes(x=Country, y=n, fill=Country)) + 
  geom_bar(stat="identity") +
  labs(title = "Top 10 Countries (excluding UK)", y="Total Lifetime Transactions") +
  theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))
```

Now that the distribution of data does not primarily fall under a single country's customer base, the analysis can proceed.

Referring back to the view of the data table, there appears to be more than $1$ observation per *InvoiceNo*. This means that the data is only grouped by *StockCode* (product) and *InvoiceNo*. In order to create a better view of each customer and their overall spending habits, some simple calculated fields are created and assigned back to the data source.

Here the *Quantity* and *UnitPrice* columns are multiplied together and assigned to a new variable called "total" in order to obtain the total cost of the items purchased per observation:

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
data_no_uk <- data_no_uk %>% mutate(total = data_no_uk$Quantity*data_no_uk$UnitPrice)
save(data_no_uk, file = "data_no_uk.RData")
```

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
head(data_no_uk,10)
```

The data is beginning to look usable and gives a more wholistic view of the customers, but there are still some improvements that can be made to ensure bias is avoided. Since the interest lies in purchasing-customer clustering, any customers or invoices that include returns or negative values for *Quantity* can be excluded from the data.

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
data_no_uk <- data_no_uk %>% subset(Quantity > 0)
save(data_no_uk, file = "data_no_uk.RData")
```

For the remainder of the analysis, only the applicable columns of interest are retained and assigned to a new data frame called *df1*.

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
df1 <- data_no_uk %>% dplyr::select(Quantity,UnitPrice,CustomerID,InvoiceDate,total)
save(df1, file = "df1.RData")
```

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
head(df1,10)
```

Next, a sum total of sales from the previously derived column *total* is created as *Sales*, along with a unique count of *InvoiceDate* to provide the number of orders made, labeled *Orders*; then the difference of those two variables is found and labeled *AvgSale*. The data is then grouped by *CustomerID* to decrease the granularity and provide a more complete view of each customer and their purchasing history and habits. This new set of data will be labeled *customer_data*:

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
customer_data <- df1 %>% group_by(CustomerID) %>% summarize(Sales=sum(total), Orders=length(unique(InvoiceDate))) %>% mutate(AvgSale=Sales/Orders)
save(customer_data, file = "customer_data.RData")
```

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
head(customer_data,10)
```

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
top5AvgValues <- top_n(customer_data, 5, AvgSale)
top5Sales <- top_n(customer_data, 5, Sales)
top5OrderCount<- top_n(customer_data,5,Orders)
bottom5AvgValues <- top_n(customer_data, -5, AvgSale)
bottom5Sales <- top_n(customer_data, -5, Sales)
options(scipen = 999)
```

Based on the newly compressed data, customers' behaviors can be visualized and subsequently used in a meaningful clustering exercise:

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
#| label: fig-charts
#| layout-ncol: 2
#| fig-cap: 
#|   - "Top 5 Avg Sales"
#|   - "Bottom 5 Avg Sales"
#|   - "Top 5 Sales"
#|   - "Bottom 5 Sales"
#|   - "Top 5 Order Frequencies"
ggplot(top5AvgValues, aes(x=reorder(CustomerID,-AvgSale),y=AvgSale, fill=as.factor(CustomerID))) + 
  geom_bar(stat="identity") +
  labs(title="Top 5 Customers by Average Sale", x="CustomerID", y="Lifetime Average") +
  theme(plot.title=element_text(size = 20)) +
  guides(fill=guide_legend(title="CustomerID"))

ggplot(bottom5AvgValues, aes(x=reorder(CustomerID,-AvgSale),y=AvgSale, fill=as.factor(CustomerID))) + 
  geom_bar(stat="identity") +
  labs(title="Bottom 5 Customers by Average Sale", x="CustomerID",y="Lifetime Average") +
  theme(plot.title=element_text(size = 20)) +
  guides(fill=guide_legend(title="CustomerID"))

ggplot(top5Sales, aes(x=reorder(CustomerID,-Sales),y=Sales, fill=as.factor(CustomerID))) + 
  geom_bar(stat="identity") +
  labs(title="Top 5 Customers by Total Sales", x="CustomerID",y="Lifetime Total Sales") +
  theme(plot.title = element_text(size = 20)) +
  guides(fill=guide_legend(title="CustomerID"))

ggplot(bottom5Sales, aes(x=reorder(CustomerID,-Sales),y=Sales, fill=as.factor(CustomerID))) +
  geom_bar(stat="identity") +
  labs(title="Bottom 5 Customers by Total Sales",x="CustomerID",y="Total Sales") +
  theme(plot.title = element_text(size = 20)) +
  guides(fill=guide_legend(title="CustomerID"))

ggplot(top5OrderCount, aes(x=reorder(CustomerID,-Orders),y=Orders, fill=as.factor(CustomerID))) + 
  geom_bar(stat="identity") +
  labs(title="Top 5 Customers by Order Count", x="CustomerID",y="Lifetime Total Orders") +
  theme(plot.title=element_text(size = 20)) +
  guides(fill=guide_legend(title="CustomerID"))
```

Having a better view and understanding of the data format and structure, the next step is to normalize the data in order to produce a normal distribution across the different variables. This is done by ranking the *Sales*, *Orders*, and *AvgSale*. Once these values have been ranked, they can be scaled for the final output. This final output is called *df_norm*.

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
df_ranked <- customer_data %>% mutate(Sales=rank(Sales), Orders=rank(Orders, ties.method = "first"), AvgSale=rank(AvgSale))
save(df_ranked, file = "df_ranked.RData")

df_norm <- df_ranked %>% mutate(Sales=scale(Sales), Orders=scale(Orders), AvgSale=scale(AvgSale))
save(df_norm, file = "df_norm.RData")
```

The resulting data is verified as normal by checking the standard deviation of each variable. Noting that *CustomerID* will not be normalized since it is an identifier for each record:

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
data.frame(sapply(df_norm, sd))
```

Now that the data is normalized, a value is determined for $k$ using the elbow method:

```{r}
# Create an empty vector to store WCSS values
wcss <- vector("numeric", length = 10)

# Iterate over a range of K values (e.g., from 1 to 10)
for (i in 1:10) {
  model <- kmeans(df_norm[c("Sales", "Orders", "AvgSale")], centers = i, nstart = 10)
  wcss[i] <- ceiling(model$tot.withinss)
}

# Plot the WCSS values against the number of clusters
ggplot(data.frame(K=1:10, WCSS=wcss), aes(x=K, y=WCSS)) +
  geom_line() +
  geom_point() +
  labs(title="Elbow Method to Find Optimal K", x="Number of Clusters (K)", y="Within-Cluster-Sum-of-Squares (WCSS)") +
  scale_x_continuous(breaks = seq(0, 10, by = 1))
```

Based on the results of the Elbow Method, above, the total within cluster sum of squares appears to decrease the least starting at $4$. This gives us the ideal starting value for the initial number of clusters in the k-means model.

To build the model, a seed is set (in order to make the results reproducible) and the model function is initialized:

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
set.seed(100)
model1 <- kmeans(df_norm[c("Sales", "Orders", "AvgSale")],4)
save(model1, file = "model1.RData")
```

The model results are presented here:

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
tidy(model1)
df_norm$Cluster <- model1$cluster
save(df_norm, file = "df_norm.RData")
```

While the model output is useful, the best visual representation of the clusters is through scatter plot.

Plot and view cluster results:

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
fviz_cluster(model1, data = df_norm,
             geom = "point",
             ellipse.type = "convex",
             ggtheme = theme_bw()
)
```

Since the model utilizes more than $2$ variables and the plot plane is two-dimensional, the axis of the graph, above, are based on principle components instead of the individual model variables.

The graph below shows the customers in relation to all three model variables in a three-dimensional scatter plot:

```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
customer_data$Cluster2 <- as.factor(model1$cluster)
save(customer_data, file = "customer_data2.RData")

axx <- list(
  nticks = 5,
  range = c(0,50)
)

axy <- list(
  nticks = 5,
  range = c(0,40000)
)

axz <- list(
  nticks = 4,
  range = c(0,4000)
)
save(axx, file = "axx.RData")
save(axy, file = "axy.RData")
save(axz, file = "axz.RData")
```

```{r, echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
#| label: model-charts
#| fig-cap: "*Interactive graph (left-click to rotate / right-click to move)*"
plot_ly(customer_data, x=~Orders, y=~Sales, z=~AvgSale,
        color=~Cluster2,
        colors=c("red","green","blue","violet")) %>% 
  add_markers(size=2) %>% 
  layout(scene = list(xaxis=axx,yaxis=axy,zaxis=axz))
```
